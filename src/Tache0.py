import pandas as pd
import numpy as np
from typing import Dict, List
from sklearn.ensemble import IsolationForest
from sklearn.svm import OneClassSVM
from scipy.stats import zscore

# Charger les donn√©es depuis le fichier openfoodfacts_sample.csv
def load_data(file_path: str = "c:/Users/emili/OneDrive/Bureau/DP2/OpenFoodFact_GroupProject/data/dataset/openfoodfacts_sample.csv") -> pd.DataFrame:
    """
    Charge les donn√©es depuis un fichier CSV.

    Args:
        file_path: Chemin du fichier CSV √† charger.
 
    Returns:
        pd.DataFrame: Le DataFrame charg√©.
    """
    print(f"Chargement des donn√©es depuis {file_path}...")
    df = pd.read_csv(file_path, sep='\t', encoding="utf-8", low_memory=True)
    print(f"‚úÖ Donn√©es charg√©es avec succ√®s : {df.shape[0]} lignes, {df.shape[1]} colonnes.")
    return df
#D√©tection des types de variables 
def detect_variable_types(df: pd.DataFrame) -> Dict:
    """
    D√©tecte les types de variables dans un DataFrame : num√©riques, cat√©gorielles nominales, ordinales.

    Args:
        df: DataFrame pandas √† analyser.

    Returns:
        Dict: Dictionnaire contenant les colonnes par type.
    """
    # Colonnes num√©riques
    numeric_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()

    # Colonnes cat√©gorielles
    categorical_columns = df.select_dtypes(include=['object', 'category']).columns.tolist()

    # Cat√©gories pr√©d√©finies pour les colonnes ordinales
    predefined_ordinal_categories = {
        "nutri_score": ["e", "d", "c", "b", "a"]
    }

    ordinal_columns = []
    non_ordinal_columns = []

    # Identifier les colonnes ordinales et non ordinales
    for col in categorical_columns:
        unique_values = df[col].dropna().astype(str).str.lower().str.strip().unique()
        
        for predefined_values in predefined_ordinal_categories.values():
            matching_values = [val for val in unique_values if val in predefined_values]
            if len(matching_values) / len(unique_values) > 0.7:  # Si 70% des valeurs correspondent
                ordinal_columns.append(col)
                break
        else:
            non_ordinal_columns.append(col)

    return {
        "numeric_columns": numeric_columns,
        "categorical_columns": categorical_columns,
        "ordinal_columns": ordinal_columns,
        "non_ordinal_columns": non_ordinal_columns
    }

# Analyse de la qualit√© des donn√©es
def analyze_data_quality(df: pd.DataFrame) -> Dict:
    """
    Analyse la qualit√© des donn√©es dans un DataFrame : dimensions, types de donn√©es,
    valeurs manquantes, valeurs uniques, colonnes constantes et utilisation m√©moire.

    Args:
        df: DataFrame pandas √† analyser
        
    Returns:
        Dict: Rapport contenant les r√©sultats de l'analyse
    """
    n_rows, n_cols = df.shape  # Dimensions du DataFrame
    dtypes = df.dtypes.value_counts()  # Comptage des types de donn√©es
    
    # Comptage des valeurs uniques par colonne
    unique_counts = df.nunique()
    unique_percentages = (unique_counts / n_rows * 100).round(2)
    
    # Colonnes constantes et avec trop de cat√©gories
    constant_columns = [col for col in df.columns if unique_counts[col] == 1]
    categorical_columns = df.select_dtypes(include=['object', 'category']).columns
    high_cardinality_columns = [col for col in categorical_columns 
                                if unique_counts[col] / n_rows > 0.5]
    
    # Colonnes num√©riques √† faible variance
    numeric_columns = df.select_dtypes(include=np.number).columns
    low_variance_columns = [col for col in numeric_columns 
                            if unique_counts[col] / n_rows < 0.01]
    
    # Utilisation de la m√©moire
    memory_usage = df.memory_usage(deep=True)
    total_memory = memory_usage.sum() / 1024**2  # M√©moire totale en Mo
    
    return {
        'dimensions': {'rows': n_rows, 'columns': n_cols},
        'dtypes': dtypes.to_dict(),
        'unique_values': {
            'counts': unique_counts.to_dict(),
            'percentages': unique_percentages.to_dict()
        },
        'quality_issues': {
            'constant_columns': constant_columns,
            'high_cardinality_columns': high_cardinality_columns,
            'low_variance_columns': low_variance_columns
        },
        'memory_usage': {
            'total_mb': total_memory,
            'per_column': memory_usage.to_dict()
        }
    }

# Exemple d'utilisation
if __name__ == "__main__":
    # Charger les donn√©es
    df = load_data()

    # D√©tection des types de variables
    print("\nüîç D√©tection des types de variables")
    variable_types = detect_variable_types(df)

    # Afficher les r√©sultats de la d√©tection
    print(f"Colonnes num√©riques : {variable_types['numeric_columns']}")
    print(f"Colonnes cat√©gorielles : {variable_types['categorical_columns']}")
    print(f"Colonnes ordinales : {variable_types['ordinal_columns']}")
    print(f"Colonnes non ordinales : {variable_types['non_ordinal_columns']}")

    # Analyse de la qualit√© des donn√©es
    print("\nüîç Analyse de la qualit√© des donn√©es")
    quality_report = analyze_data_quality(df)

    # Affichage structur√© des r√©sultats
    print("\nüìä R√©sultats de l'analyse de la qualit√© des donn√©es :")

    # Dimensions
    print("\nüîπ Dimensions :")
    print(f"Nombre de lignes : {quality_report['dimensions']['rows']}")
    print(f"Nombre de colonnes : {quality_report['dimensions']['columns']}")

    # Types de donn√©es
    print("\nüîπ Types de donn√©es :")
    for dtype, count in quality_report['dtypes'].items():
        print(f"{dtype}: {count}")

    

    # Valeurs uniques
    print("\nüîπ Valeurs uniques :")
    print("Nombre de valeurs uniques par colonne :")
    for col, count in quality_report['unique_values']['counts'].items():
        percentage = quality_report['unique_values']['percentages'][col]
        print(f"- {col} : {count} valeurs uniques ({percentage}%)")

    # Probl√®mes de qualit√©
    print("\nüîπ Probl√®mes de qualit√© :")
    print(f"Colonnes constantes : {quality_report['quality_issues']['constant_columns']}")
    print(f"Colonnes avec une forte cardinalit√© : {quality_report['quality_issues']['high_cardinality_columns']}")
    print(f"Colonnes num√©riques √† faible variance : {quality_report['quality_issues']['low_variance_columns']}")

    # Utilisation de la m√©moire
    print("\nüîπ Utilisation de la m√©moire :")
    print(f"Utilisation totale de la m√©moire : {quality_report['memory_usage']['total_mb']:.2f} Mo")
    print("Utilisation de la m√©moire par colonne :")
    for col, memory in quality_report['memory_usage']['per_column'].items():
        print(f"- {col} : {memory / 1024:.2f} Ko")

    
